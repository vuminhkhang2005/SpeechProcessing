# Speech Denoising Configuration

# Dataset paths
# Option 1: Local paths (default)
# Option 2: Google Drive paths (for Colab) - set use_gdrive: true
data:
  # Set to true to use Google Drive dataset (for Google Colab)
  use_gdrive: false
  
  # Google Drive settings (only used if use_gdrive: true)
  gdrive:
    # Path to dataset folder in Google Drive
    # Thư mục chứa: clean_trainset_28spk_wav, noisy_trainset_28spk_wav, etc.
    path: "/content/drive/MyDrive/speech_denoising_data"
    # Folder ID from the Drive URL (backup option)
    folder_id: "1mDHfxtzvC-7kw0YXF0dFAcYlh7GAb2-"
  
  # Local paths (used if use_gdrive: false)
  # Đường dẫn tới thư mục chứa VoiceBank + DEMAND dataset
  train_clean_dir: "./data/clean_trainset_28spk_wav"
  train_noisy_dir: "./data/noisy_trainset_28spk_wav"
  test_clean_dir: "./data/clean_testset_wav"
  test_noisy_dir: "./data/noisy_testset_wav"
  
  # Audio parameters
  sample_rate: 16000
  segment_length: 32000  # 2 seconds at 16kHz
  
  # Normalization settings - QUAN TRỌNG!
  # Sử dụng global normalization thay vì per-file normalization
  # Theo bioacoustics.stackexchange.com, điều này ngăn file yên tĩnh bị khuếch đại sai
  use_global_norm: true
  normalizer_path: "./data/normalizer_stats.json"
  
  # Data augmentation (only during training)
  augment: true
  augment_prob: 0.5
  
# STFT parameters
stft:
  n_fft: 512
  hop_length: 128
  win_length: 512

# Model parameters
model:
  name: "UNetDenoiser"
  # Encoder channels
  encoder_channels: [1, 32, 64, 128, 256, 512]
  # Use attention in bottleneck
  use_attention: true
  # Dropout rate
  dropout: 0.1

# Training parameters
training:
  batch_size: 16
  # Tăng số epochs để model có đủ thời gian học
  # Theo ai.stackexchange.com, có thể cần >=100 epochs cho speech denoising
  num_epochs: 150
  learning_rate: 0.0001
  weight_decay: 0.00001
  
  # Learning rate scheduler - ReduceLROnPlateau
  # Giảm learning rate khi validation loss không cải thiện
  scheduler:
    name: "ReduceLROnPlateau"
    patience: 8           # Epochs to wait before reducing LR
    factor: 0.5           # LR *= factor when plateau
    min_lr: 0.000001      # Minimum learning rate
  
  # Early stopping - CẢI TIẾN theo keras.io
  # Tăng patience để train đủ lâu
  early_stopping:
    patience: 20          # Số epochs chờ trước khi dừng (tăng từ 15)
    min_delta: 0.0001     # Ngưỡng cải thiện tối thiểu
    restore_best_weights: true  # QUAN TRỌNG! Khôi phục best weights khi dừng
  
  # Backward compatibility
  early_stopping_patience: 20
  
  # Gradient clipping
  grad_clip: 5.0
  # Number of workers for data loading
  num_workers: 4
  # Mixed precision training
  use_amp: true

# Loss function - CẢI TIẾN ĐỂ NGĂN LAZY LEARNING
# Theo ai.stackexchange.com, MSE với activation phù hợp thường tốt hơn Binary Crossentropy
# SI-SDR là loss scale-invariant - không quan tâm âm lượng, chỉ quan tâm chất lượng
loss:
  # STFT domain losses
  l1_weight: 1.0           # Complex L1 loss weight
  magnitude_weight: 1.0    # Magnitude loss weight
  stft_weight: 0.5         # Multi-resolution STFT loss weight
  
  # Time domain losses - QUAN TRỌNG để ngăn lazy learning!
  # SI-SDR loss: Nếu model chỉ giảm volume, SI-SDR sẽ KHÔNG cải thiện
  # Đây là key để ngăn "lazy learning" pattern
  si_sdr_weight: 0.7       # Tăng weight cho SI-SDR (từ 0.5 lên 0.7)
  time_l1_weight: 0.3      # Time domain L1 loss
  
  # Regularization - ngăn model giảm volume quá nhiều
  # Energy ratio giữa output/input nên trong khoảng [0.7, 1.3]
  energy_weight: 0.2       # Tăng weight (từ 0.1 lên 0.2)

# Checkpoints and logging
checkpoint:
  save_dir: "./checkpoints"
  save_every: 5  # Save every N epochs
  keep_last: 3   # Keep last N checkpoints

logging:
  log_dir: "./logs"
  log_every: 100  # Log every N steps

# Evaluation
eval:
  output_dir: "./outputs"
  # Calculate metrics
  # Note: PESQ requires the 'pesq' package which needs C compilation.
  # On Windows, this requires Microsoft Visual C++ Build Tools.
  # If pesq is not installed, PESQ metrics will be skipped automatically.
  compute_pesq: true
  compute_stoi: true
