# Speech Denoising Configuration
# CẢI TIẾN: Tối ưu hóa theo các best practices cho speech enhancement

# Dataset paths
# Option 1: Local paths (default)
# Option 2: Google Drive paths (for Colab) - set use_gdrive: true
data:
  # Set to true to use Google Drive dataset (for Google Colab)
  use_gdrive: false
  
  # Google Drive settings (only used if use_gdrive: true)
  gdrive:
    # Path to dataset folder in Google Drive
    # Thư mục chứa: clean_trainset_28spk_wav, noisy_trainset_28spk_wav, etc.
    path: "/content/drive/MyDrive/speech_denoising_data"
    # Folder ID from the Drive URL (backup option)
    folder_id: "1mDHfxtzvC-7kw0YXF0dFAcYlh7GAb2-"
  
  # Local paths (used if use_gdrive: false)
  # Đường dẫn tới thư mục chứa VoiceBank + DEMAND dataset
  train_clean_dir: "./data/clean_trainset_28spk_wav"
  train_noisy_dir: "./data/noisy_trainset_28spk_wav"
  test_clean_dir: "./data/clean_testset_wav"
  test_noisy_dir: "./data/noisy_testset_wav"
  
  # Audio parameters
  sample_rate: 16000
  segment_length: 32000  # 2 seconds at 16kHz
  
  # Data normalization - QUAN TRỌNG!
  # Sử dụng global normalization thay vì per-file normalization
  normalization:
    method: "global"  # "global", "per_file", or "none"
    # Global statistics (sẽ được tự động tính nếu chưa có)
    # Nếu không có file normalizer_stats.json, sử dụng giá trị mặc định này
    default_mean: 0.0
    default_std: 0.05

# STFT parameters
stft:
  n_fft: 512
  hop_length: 128
  win_length: 512

# Model parameters
model:
  name: "UNetDenoiser"
  # Encoder channels - kiến trúc U-Net
  # [32, 64, 128, 256, 512] là cấu hình balanced giữa quality và speed
  encoder_channels: [32, 64, 128, 256, 512]
  # Use attention in bottleneck - giúp capture long-range dependencies
  use_attention: true
  # Dropout rate - giảm overfitting
  dropout: 0.1
  # Mask type: 'CRM' (Complex Ratio Mask) hoặc 'IRM' (Ideal Ratio Mask)
  mask_type: "CRM"

# Training parameters - CẢI TIẾN
training:
  batch_size: 16
  num_epochs: 150  # Tăng từ 100 lên 150 để train đủ lâu
  learning_rate: 0.0001
  weight_decay: 0.00001
  
  # Learning rate scheduler - CẢI TIẾN
  scheduler:
    name: "ReduceLROnPlateau"
    patience: 7        # Epochs trước khi giảm LR
    factor: 0.5        # Giảm LR xuống còn 50%
    min_lr: 0.000001   # LR tối thiểu
    cooldown: 2        # Epochs nghỉ sau khi giảm LR
  
  # Early stopping - CẢI TIẾN để ngăn dừng quá sớm
  early_stopping_patience: 20    # Tăng từ 15 lên 20
  early_stopping_min_delta: 0.0001  # Minimum improvement để tính là improvement
  restore_best_weights: true     # QUAN TRỌNG: Load lại best weights khi stop
  
  # Gradient clipping
  grad_clip: 5.0
  
  # Number of workers for data loading
  num_workers: 4
  
  # Mixed precision training (AMP) - giúp train nhanh hơn
  use_amp: true

# Loss function - CẢI TIẾN ĐỂ NGĂN LAZY LEARNING
# Lazy learning = model chỉ giảm volume thay vì thực sự lọc noise
loss:
  # === STFT Domain Losses ===
  l1_weight: 1.0           # Complex L1 loss weight
  magnitude_weight: 1.0    # Magnitude loss weight
  stft_weight: 0.5         # Multi-resolution STFT loss weight
  
  # === Time Domain Losses - QUAN TRỌNG! ===
  # SI-SDR loss là KEY để ngăn lazy learning
  # SI-SDR là scale-invariant, không quan tâm volume, chỉ quan tâm chất lượng
  si_sdr_weight: 0.7       # Tăng từ 0.5 lên 0.7 (quan trọng nhất!)
  time_l1_weight: 0.3      # Time domain L1 loss
  
  # === Regularization ===
  # Energy conservation: ngăn model giảm volume quá nhiều
  energy_weight: 0.15      # Tăng từ 0.1 lên 0.15
  
  # Tóm tắt: Total loss = 
  #   l1_weight * complex_l1 + 
  #   magnitude_weight * magnitude_l1 +
  #   stft_weight * mr_stft +
  #   si_sdr_weight * (-SI_SDR) +      <- Quan trọng nhất!
  #   time_l1_weight * time_l1 +
  #   energy_weight * energy_penalty

# Checkpoints and logging
checkpoint:
  save_dir: "./checkpoints"
  save_every: 5  # Save every N epochs
  keep_last: 3   # Keep last N checkpoints

logging:
  log_dir: "./logs"
  log_every: 100  # Log every N steps

# Evaluation
eval:
  output_dir: "./outputs"
  # Calculate metrics
  # Note: PESQ requires the 'pesq' package which needs C compilation.
  # On Windows, this requires Microsoft Visual C++ Build Tools.
  # If pesq is not installed, PESQ metrics will be skipped automatically.
  compute_pesq: true
  compute_stoi: true
  
  # Audio output settings
  output:
    # Normalize output audio after inference
    normalize_output: true
    # Target dB level for output normalization (-25 dB là standard)
    target_db: -25.0
    # Prevent clipping
    prevent_clipping: true
