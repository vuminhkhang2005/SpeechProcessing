#!/usr/bin/env python3
"""
Script ki·ªÉm tra ch·∫•t l∆∞·ª£ng model - Ph√°t hi·ªán "Lazy Learning"

Lazy Learning l√† khi model ch·ªâ gi·∫£m √¢m l∆∞·ª£ng thay v√¨ th·ª±c s·ª± l·ªçc ·ªìn.

C√°c ti√™u ch√≠ ki·ªÉm tra:
1. Energy Ratio: NƒÉng l∆∞·ª£ng output so v·ªõi clean (n√™n g·∫ßn 1.0)
2. Noise Reduction: L∆∞·ª£ng noise ƒë∆∞·ª£c lo·∫°i b·ªè (n√™n > 50%)
3. SI-SDR: Ch·∫•t l∆∞·ª£ng t√≠n hi·ªáu (c√†ng cao c√†ng t·ªët)
4. STOI: ƒê·ªô hi·ªÉu c·ªßa gi·ªçng n√≥i (c√†ng cao c√†ng t·ªët)
5. PESQ: Perceptual quality (n·∫øu c√≥ c√†i ƒë·∫∑t)

C·∫£i ti·∫øn:
- S·ª≠ d·ª•ng librosa thay v√¨ torchaudio (Google Colab compatible)
- Th√™m STOI v√† PESQ metrics
- Th√™m post-processing detection
- Th√™m volume matching analysis

C√°ch s·ª≠ d·ª•ng:
    python test_model_quality.py --checkpoint checkpoints/best_model.pt
    python test_model_quality.py --checkpoint checkpoints/best_model.pt --noisy test.wav --clean clean.wav
"""

import argparse
import sys
from pathlib import Path
import numpy as np
import torch
import librosa
import soundfile as sf

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

from models.unet import load_model_checkpoint
from utils.audio_utils import AudioProcessor, post_process_denoised, match_amplitude
from utils.metrics import calculate_si_sdr, calculate_stoi, is_pesq_available, calculate_pesq


def calculate_energy(signal: np.ndarray) -> float:
    """Calculate signal energy"""
    return np.sum(signal ** 2)


def calculate_rms(signal: np.ndarray) -> float:
    """Calculate RMS amplitude"""
    return np.sqrt(np.mean(signal ** 2))


def diagnose_lazy_learning(
    noisy: np.ndarray,
    clean: np.ndarray,
    output: np.ndarray,
    sample_rate: int = 16000
) -> dict:
    """
    Ch·∫©n ƒëo√°n xem model c√≥ ƒëang "lazy learning" kh√¥ng
    
    Args:
        noisy: Noisy input signal
        clean: Clean reference signal
        output: Model output signal
        sample_rate: Sample rate
    
    Returns:
        Dictionary with diagnostic metrics
    """
    results = {}
    
    # 1. Energy ratio (output vs clean)
    # N·∫øu model ch·ªâ gi·∫£m volume, energy_ratio s·∫Ω < 1.0 nhi·ªÅu
    output_energy = calculate_energy(output)
    clean_energy = calculate_energy(clean)
    noisy_energy = calculate_energy(noisy)
    
    results['energy_ratio_vs_clean'] = output_energy / (clean_energy + 1e-8)
    results['energy_ratio_vs_noisy'] = output_energy / (noisy_energy + 1e-8)
    
    # 2. RMS ratio
    output_rms = calculate_rms(output)
    clean_rms = calculate_rms(clean)
    noisy_rms = calculate_rms(noisy)
    
    results['rms_ratio_vs_clean'] = output_rms / (clean_rms + 1e-8)
    results['rms_ratio_vs_noisy'] = output_rms / (noisy_rms + 1e-8)
    
    # 3. Noise reduction ratio
    # noise_in = noisy - clean
    # noise_out = output - clean
    noise_in = noisy - clean
    noise_out = output - clean
    
    noise_in_energy = calculate_energy(noise_in)
    noise_out_energy = calculate_energy(noise_out)
    
    results['noise_reduction_ratio'] = 1 - (noise_out_energy / (noise_in_energy + 1e-8))
    
    # 4. SI-SDR
    results['si_sdr_input'] = calculate_si_sdr(clean, noisy)
    results['si_sdr_output'] = calculate_si_sdr(clean, output)
    results['si_sdr_improvement'] = results['si_sdr_output'] - results['si_sdr_input']
    
    # 5. Correlation v·ªõi clean v√† noisy
    results['correlation_with_clean'] = np.corrcoef(output.flatten(), clean.flatten())[0, 1]
    results['correlation_with_noisy'] = np.corrcoef(output.flatten(), noisy.flatten())[0, 1]
    
    # 6. STOI (Short-Time Objective Intelligibility)
    try:
        results['stoi_input'] = calculate_stoi(clean, noisy, sample_rate)
        results['stoi_output'] = calculate_stoi(clean, output, sample_rate)
        results['stoi_improvement'] = results['stoi_output'] - results['stoi_input']
    except Exception as e:
        print(f"   STOI calculation failed: {e}")
        results['stoi_input'] = 0.0
        results['stoi_output'] = 0.0
        results['stoi_improvement'] = 0.0
    
    # 7. PESQ (if available)
    if is_pesq_available():
        try:
            results['pesq_input'] = calculate_pesq(clean, noisy, sample_rate)
            results['pesq_output'] = calculate_pesq(clean, output, sample_rate)
            if results['pesq_input'] and results['pesq_output']:
                results['pesq_improvement'] = results['pesq_output'] - results['pesq_input']
        except Exception as e:
            print(f"   PESQ calculation failed: {e}")
    
    return results


def interpret_results(results: dict) -> str:
    """Di·ªÖn gi·∫£i k·∫øt qu·∫£ ch·∫©n ƒëo√°n"""
    
    issues = []
    good_signs = []
    
    # 1. Check energy ratio
    energy_ratio = results['energy_ratio_vs_clean']
    if energy_ratio < 0.5:
        issues.append(f"‚ö†Ô∏è LAZY LEARNING: Output energy qu√° nh·ªè ({energy_ratio:.2f}x so v·ªõi clean)")
        issues.append("   ‚Üí Model ƒëang ch·ªâ gi·∫£m volume thay v√¨ l·ªçc noise!")
    elif energy_ratio < 0.7:
        issues.append(f"‚ö†Ô∏è Output energy h∆°i th·∫•p ({energy_ratio:.2f}x so v·ªõi clean)")
    elif 0.8 <= energy_ratio <= 1.2:
        good_signs.append(f"‚úÖ Energy ratio t·ªët: {energy_ratio:.2f}x")
    elif energy_ratio > 1.5:
        issues.append(f"‚ö†Ô∏è Output energy qu√° cao ({energy_ratio:.2f}x)")
    
    # 2. Check noise reduction
    noise_reduction = results['noise_reduction_ratio']
    if noise_reduction < 0.2:
        issues.append(f"‚ö†Ô∏è Noise reduction r·∫•t k√©m: ch·ªâ gi·∫£m {noise_reduction*100:.1f}% noise")
    elif noise_reduction < 0.5:
        issues.append(f"‚ö†Ô∏è Noise reduction th·∫•p: gi·∫£m {noise_reduction*100:.1f}% noise")
    else:
        good_signs.append(f"‚úÖ Noise reduction: {noise_reduction*100:.1f}%")
    
    # 3. Check SI-SDR improvement
    sdr_improvement = results['si_sdr_improvement']
    if sdr_improvement < 0:
        issues.append(f"‚ö†Ô∏è SI-SDR gi·∫£m {abs(sdr_improvement):.2f} dB! Output t·ªá h∆°n input!")
    elif sdr_improvement < 3:
        issues.append(f"‚ö†Ô∏è SI-SDR c·∫£i thi·ªán √≠t: ch·ªâ +{sdr_improvement:.2f} dB")
    else:
        good_signs.append(f"‚úÖ SI-SDR c·∫£i thi·ªán: +{sdr_improvement:.2f} dB")
    
    # 4. Check STOI improvement (if available)
    if 'stoi_improvement' in results and results.get('stoi_output', 0) > 0:
        stoi_improvement = results['stoi_improvement']
        stoi_output = results['stoi_output']
        if stoi_improvement < -0.05:
            issues.append(f"‚ö†Ô∏è STOI gi·∫£m {abs(stoi_improvement):.3f}! ƒê·ªô hi·ªÉu gi·∫£m!")
        elif stoi_output > 0.9:
            good_signs.append(f"‚úÖ STOI r·∫•t t·ªët: {stoi_output:.3f} (c·∫£i thi·ªán +{stoi_improvement:.3f})")
        elif stoi_output > 0.7:
            good_signs.append(f"‚úÖ STOI kh√°: {stoi_output:.3f}")
        else:
            issues.append(f"‚ö†Ô∏è STOI th·∫•p: {stoi_output:.3f}")
    
    # 5. Check PESQ improvement (if available)
    if 'pesq_improvement' in results:
        pesq_improvement = results['pesq_improvement']
        pesq_output = results.get('pesq_output', 0)
        if pesq_improvement < -0.2:
            issues.append(f"‚ö†Ô∏è PESQ gi·∫£m {abs(pesq_improvement):.2f}!")
        elif pesq_output > 3.5:
            good_signs.append(f"‚úÖ PESQ t·ªët: {pesq_output:.2f} (c·∫£i thi·ªán +{pesq_improvement:.2f})")
        elif pesq_output > 2.5:
            good_signs.append(f"‚úÖ PESQ kh√°: {pesq_output:.2f}")
    
    # 6. Check correlation pattern
    corr_clean = results['correlation_with_clean']
    corr_noisy = results['correlation_with_noisy']
    
    if corr_noisy > corr_clean:
        issues.append(f"‚ö†Ô∏è Output gi·ªëng noisy ({corr_noisy:.3f}) h∆°n clean ({corr_clean:.3f})")
        issues.append("   ‚Üí Model ch∆∞a h·ªçc ƒë∆∞·ª£c c√°ch l·ªçc noise!")
    else:
        good_signs.append(f"‚úÖ Output gi·ªëng clean ({corr_clean:.3f}) h∆°n noisy ({corr_noisy:.3f})")
    
    # Build interpretation
    interpretation = "\n" + "="*60 + "\n"
    interpretation += "CH·∫®N ƒêO√ÅN MODEL\n"
    interpretation += "="*60 + "\n\n"
    
    if good_signs:
        interpretation += "üü¢ D·∫§U HI·ªÜU T·ªêT:\n"
        for sign in good_signs:
            interpretation += f"   {sign}\n"
        interpretation += "\n"
    
    if issues:
        interpretation += "üî¥ V·∫§N ƒê·ªÄ:\n"
        for issue in issues:
            interpretation += f"   {issue}\n"
        interpretation += "\n"
        
        interpretation += "üí° G·ª¢I √ù S·ª¨A:\n"
        if any("LAZY LEARNING" in i for i in issues):
            interpretation += """
   1. S·ª≠ d·ª•ng SI-SDR loss (ƒë√£ ƒë∆∞·ª£c th√™m v√†o models/loss.py)
   2. TƒÉng si_sdr_weight trong config.yaml (0.5 ‚Üí 1.0)
   3. Train l√¢u h∆°n (100-150 epochs)
   4. Gi·∫£m learning rate (0.0001 ‚Üí 0.00005)
   5. Ki·ªÉm tra dataset c√≥ ƒë√∫ng kh√¥ng (clean ph·∫£i th·ª±c s·ª± s·∫°ch)
   6. TƒÉng energy_weight trong config.yaml (0.1 ‚Üí 0.2)
"""
        elif any("c·∫£i thi·ªán √≠t" in i for i in issues):
            interpretation += """
   1. Train th√™m epochs (100-150 epochs)
   2. TƒÉng model capacity (encoder_channels l·ªõn h∆°n)
   3. Ki·ªÉm tra xem val_loss c√≥ ƒëang gi·∫£m kh√¥ng
   4. Th·ª≠ tƒÉng learning rate m·ªôt ch√∫t
"""
        elif any("STOI" in i or "PESQ" in i for i in issues):
            interpretation += """
   1. Model c√≥ th·ªÉ ƒëang over-smooth t√≠n hi·ªáu
   2. Th·ª≠ gi·∫£m magnitude_weight, tƒÉng si_sdr_weight
   3. Ki·ªÉm tra STFT parameters (n_fft, hop_length)
"""
    else:
        interpretation += "üéâ Model ho·∫°t ƒë·ªông t·ªët!\n"
    
    return interpretation


def process_file(
    model,
    audio_processor: AudioProcessor,
    input_path: str,
    clean_path: str = None,
    device: torch.device = None,
    apply_postprocess: bool = True
) -> dict:
    """
    Process a single file and run diagnostics
    
    Args:
        model: UNet model
        audio_processor: AudioProcessor instance
        input_path: Path to noisy audio
        clean_path: Path to clean reference (optional)
        device: Torch device
        apply_postprocess: Apply post-processing to match input loudness
    
    Returns:
        Dictionary with audio arrays and diagnostics
    """
    
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # Load noisy audio using librosa (Google Colab compatible)
    noisy_np, sr = librosa.load(input_path, sr=16000, mono=True)
    noisy_wav = torch.from_numpy(noisy_np).float().unsqueeze(0)  # [1, samples]
    
    # Load clean audio if available
    if clean_path and Path(clean_path).exists():
        clean_np, _ = librosa.load(clean_path, sr=16000, mono=True)
        clean_wav = torch.from_numpy(clean_np).float().unsqueeze(0)
    else:
        clean_wav = None
        clean_np = None
        print("‚ö†Ô∏è Kh√¥ng c√≥ clean reference, m·ªôt s·ªë metrics s·∫Ω kh√¥ng t√≠nh ƒë∆∞·ª£c")
    
    # Process with model
    model.eval()
    with torch.no_grad():
        noisy_stft = audio_processor.stft(noisy_wav)
        noisy_stft = noisy_stft.permute(0, 3, 1, 2).to(device)
        
        pred_stft = model(noisy_stft)
        
        pred_stft = pred_stft.permute(0, 2, 3, 1).cpu()
        output_wav = audio_processor.istft(pred_stft)
    
    # Convert to numpy
    output_np = output_wav.numpy().flatten()
    
    # Ensure same length
    min_len = min(len(noisy_np), len(output_np))
    noisy_np = noisy_np[:min_len]
    output_np = output_np[:min_len]
    
    # Apply post-processing to match input loudness
    # ƒêi·ªÅu n√†y gi√∫p tr√°nh v·∫•n ƒë·ªÅ "√¢m l∆∞·ª£ng gi·∫£m" sau kh·ª≠ nhi·ªÖu
    if apply_postprocess:
        output_np_original = output_np.copy()
        output_np = match_amplitude(output_np, noisy_np, method='rms')
        
        # Report loudness change
        rms_before = calculate_rms(output_np_original)
        rms_after = calculate_rms(output_np)
        if abs(rms_after - rms_before) / (rms_before + 1e-8) > 0.1:
            print(f"   üìä Post-processing: amplitude adjusted by {(rms_after/rms_before - 1)*100:+.1f}%")
    
    results = {
        'noisy': noisy_np,
        'output': output_np,
        'output_raw': output_np_original if apply_postprocess else output_np
    }
    
    if clean_np is not None:
        clean_np = clean_np[:min_len]
        results['clean'] = clean_np
        
        # Run diagnostics on BOTH raw and post-processed output
        results['diagnostics'] = diagnose_lazy_learning(noisy_np, clean_np, output_np)
        
        if apply_postprocess:
            results['diagnostics_raw'] = diagnose_lazy_learning(
                noisy_np, clean_np, output_np_original if apply_postprocess else output_np
            )
    
    return results


def main():
    parser = argparse.ArgumentParser(description='Test model quality - Detect lazy learning')
    parser.add_argument('--checkpoint', type=str, required=True,
                        help='Path to model checkpoint')
    parser.add_argument('--noisy', type=str, default=None,
                        help='Path to noisy audio file')
    parser.add_argument('--clean', type=str, default=None,
                        help='Path to clean reference audio file')
    parser.add_argument('--test_dir', type=str, default='./data/noisy_testset_wav',
                        help='Directory with test files (if no --noisy specified)')
    parser.add_argument('--clean_dir', type=str, default='./data/clean_testset_wav',
                        help='Directory with clean reference files')
    parser.add_argument('--num_samples', type=int, default=5,
                        help='Number of samples to test')
    parser.add_argument('--save_output', type=str, default=None,
                        help='Path to save output audio')
    
    args = parser.parse_args()
    
    print("="*60)
    print("KI·ªÇM TRA CH·∫§T L∆Ø·ª¢NG MODEL - PH√ÅT HI·ªÜN LAZY LEARNING")
    print("="*60)
    
    # Setup device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nDevice: {device}")
    
    # Load model
    print(f"Loading model from: {args.checkpoint}")
    model, config = load_model_checkpoint(args.checkpoint, device)
    model.eval()
    
    # Setup audio processor
    stft_cfg = config.get('stft', {})
    audio_processor = AudioProcessor(
        n_fft=stft_cfg.get('n_fft', 512),
        hop_length=stft_cfg.get('hop_length', 128),
        win_length=stft_cfg.get('win_length', 512)
    )
    
    # Process files
    if args.noisy:
        # Single file mode
        print(f"\nProcessing: {args.noisy}")
        results = process_file(model, audio_processor, args.noisy, args.clean, device)
        
        if 'diagnostics' in results:
            print("\nüìä K·∫æT QU·∫¢ CH·∫®N ƒêO√ÅN:")
            diag = results['diagnostics']
            print(f"   Energy ratio (vs clean): {diag['energy_ratio_vs_clean']:.3f}")
            print(f"   RMS ratio (vs clean): {diag['rms_ratio_vs_clean']:.3f}")
            print(f"   Noise reduction: {diag['noise_reduction_ratio']*100:.1f}%")
            print(f"   SI-SDR input: {diag['si_sdr_input']:.2f} dB")
            print(f"   SI-SDR output: {diag['si_sdr_output']:.2f} dB")
            print(f"   SI-SDR improvement: {diag['si_sdr_improvement']:+.2f} dB")
            print(f"   Correlation with clean: {diag['correlation_with_clean']:.3f}")
            print(f"   Correlation with noisy: {diag['correlation_with_noisy']:.3f}")
            
            print(interpret_results(diag))
        
        # Save output if requested
        if args.save_output:
            # Use soundfile for saving (Google Colab compatible)
            sf.write(args.save_output, results['output'], 16000)
            print(f"\nüíæ Output saved to: {args.save_output}")
            
            # Also save raw (before post-processing) for comparison
            if 'output_raw' in results:
                raw_path = args.save_output.replace('.wav', '_raw.wav')
                sf.write(raw_path, results['output_raw'], 16000)
                print(f"üíæ Raw output saved to: {raw_path}")
    
    else:
        # Batch mode - test multiple files
        test_dir = Path(args.test_dir)
        clean_dir = Path(args.clean_dir)
        
        if not test_dir.exists():
            print(f"‚ö†Ô∏è Test directory not found: {test_dir}")
            print("Vui l√≤ng ch·ªâ ƒë·ªãnh --noisy ho·∫∑c download dataset tr∆∞·ªõc")
            return
        
        test_files = list(test_dir.glob('*.wav'))[:args.num_samples]
        
        all_diagnostics = []
        
        for test_file in test_files:
            print(f"\nProcessing: {test_file.name}")
            
            # Find matching clean file
            clean_file = clean_dir / test_file.name
            clean_path = str(clean_file) if clean_file.exists() else None
            
            try:
                results = process_file(
                    model, audio_processor, 
                    str(test_file), clean_path, device
                )
                
                if 'diagnostics' in results:
                    diag = results['diagnostics']
                    all_diagnostics.append(diag)
                    
                    print(f"   Energy ratio: {diag['energy_ratio_vs_clean']:.3f}")
                    print(f"   Noise reduction: {diag['noise_reduction_ratio']*100:.1f}%")
                    print(f"   SI-SDR improvement: {diag['si_sdr_improvement']:+.2f} dB")
                    
            except Exception as e:
                print(f"   Error: {e}")
        
        # Summary
        if all_diagnostics:
            print("\n" + "="*60)
            print("T·ªîNG K·∫æT")
            print("="*60)
            
            avg_energy = np.mean([d['energy_ratio_vs_clean'] for d in all_diagnostics])
            avg_noise_reduction = np.mean([d['noise_reduction_ratio'] for d in all_diagnostics])
            avg_sdr_improvement = np.mean([d['si_sdr_improvement'] for d in all_diagnostics])
            
            print(f"\nüìä Trung b√¨nh tr√™n {len(all_diagnostics)} files:")
            print(f"   Energy ratio: {avg_energy:.3f}")
            print(f"   Noise reduction: {avg_noise_reduction*100:.1f}%")
            print(f"   SI-SDR improvement: {avg_sdr_improvement:+.2f} dB")
            
            # Overall interpretation
            fake_diag = {
                'energy_ratio_vs_clean': avg_energy,
                'noise_reduction_ratio': avg_noise_reduction,
                'si_sdr_improvement': avg_sdr_improvement,
                'correlation_with_clean': np.mean([d['correlation_with_clean'] for d in all_diagnostics]),
                'correlation_with_noisy': np.mean([d['correlation_with_noisy'] for d in all_diagnostics])
            }
            print(interpret_results(fake_diag))


if __name__ == '__main__':
    main()
