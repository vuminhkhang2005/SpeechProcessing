# Speech Denoising

A deep learning-based speech denoising system using U-Net architecture for removing background noise from audio recordings.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/speech_denoising/blob/main/train_colab.ipynb)

## Overview

This project implements a **speech enhancement/denoising** system that removes background noise while preserving speech quality. It uses a U-Net convolutional neural network operating on STFT spectrograms.

### Key Features

- **U-Net Architecture**: Encoder-decoder network with skip connections for preserving fine details
- **Complex Ratio Mask (CRM)**: Applies learned masks to both real and imaginary STFT components
- **Self-Attention**: Optional attention mechanism in the bottleneck for capturing long-range dependencies
- **Multi-Resolution STFT Loss**: Combined L1 and spectral loss for better perceptual quality
- **Anti-Lazy Learning**: SI-SDR loss v√† Energy Conservation Loss ƒë·ªÉ ngƒÉn model ch·ªâ gi·∫£m volume
- **Global Normalization**: Chu·∫©n h√≥a theo mean/std c·ªßa training set (theo khuy·∫øn c√°o c·ªßa LeCun)
- **Post-Processing**: Amplitude matching ƒë·ªÉ output c√≥ c√πng loudness v·ªõi input
- **GUI Application**: User-friendly interface built with tkinter
- **Real-time Demo**: Live microphone denoising capability

## Architecture

```
Audio (noisy) ‚Üí STFT ‚Üí U-Net (Encoder ‚Üí Bottleneck ‚Üí Decoder) ‚Üí Mask ‚Üí iSTFT ‚Üí Audio (clean)
```

The model processes complex STFT spectrograms (real + imaginary parts) and predicts a mask that is applied to enhance the speech signal.

### Model Details

- **Input**: Complex STFT [batch, 2, freq, time]
- **Encoder**: 5 stages with channels [32, 64, 128, 256, 512]
- **Bottleneck**: 1024 channels with optional self-attention
- **Decoder**: Mirrors encoder with skip connections
- **Output**: Enhanced complex STFT (same shape as input)
- **Parameters**: ~26M trainable parameters

## Installation

### Requirements

- Python 3.8+
- PyTorch 1.9+
- CUDA (optional, for GPU acceleration)

### Setup

```bash
# Clone the repository
git clone <repo-url>
cd speech_denoising

# Install dependencies
pip install -r requirements.txt
```

## Dataset

This project uses the **VoiceBank + DEMAND** dataset, widely used in speech enhancement research.

- **Clean speech**: VoiceBank corpus
- **Noise**: DEMAND database
- **Sample rate**: 16 kHz

### Option 1: Local Download

Download from: https://datashare.ed.ac.uk/handle/10283/2791

After downloading, organize the data as follows:

```
speech_denoising/
‚îî‚îÄ‚îÄ data/
    ‚îú‚îÄ‚îÄ clean_trainset_28spk_wav/
    ‚îú‚îÄ‚îÄ noisy_trainset_28spk_wav/
    ‚îú‚îÄ‚îÄ clean_testset_wav/
    ‚îî‚îÄ‚îÄ noisy_testset_wav/
```

### Option 2: Google Drive (for Colab)

Upload your dataset to Google Drive with this structure:

```
My Drive/
‚îî‚îÄ‚îÄ datasets/                          # Your dataset folder
    ‚îú‚îÄ‚îÄ clean_trainset_28spk_wav/      # 11,572 .wav files
    ‚îú‚îÄ‚îÄ noisy_trainset_28spk_wav/      # 11,572 .wav files
    ‚îú‚îÄ‚îÄ clean_testset_wav/             # 824 .wav files
    ‚îî‚îÄ‚îÄ noisy_testset_wav/             # 824 .wav files
```

Then use in Colab:
```python
from data.dataset import setup_gdrive_dataset, create_dataloaders

# Setup dataset from Google Drive
paths = setup_gdrive_dataset(gdrive_path='/content/drive/MyDrive/datasets')

# Create dataloaders
train_loader, val_loader = create_dataloaders(**paths)
```

## Usage

### Training

Train the model with default configuration:

```bash
python train.py --config config.yaml
```

Resume training from a checkpoint:

```bash
python train.py --config config.yaml --resume checkpoints/model_epoch_20.pt
```

### üöÄ Train on Google Colab with Google Drive Dataset (Recommended)

Train the model for free on Google Colab with GPU acceleration, using your dataset from Google Drive:

1. **Upload dataset to Google Drive**: Upload the VoiceBank + DEMAND dataset to your Google Drive (see Dataset section above)

2. **Open the notebook**: Click the "Open in Colab" badge at the top of this README, or upload `train_colab.ipynb` to Google Colab

3. **Enable GPU**: Go to `Runtime` ‚Üí `Change runtime type` ‚Üí Select `GPU`

4. **Configure dataset path**: In the notebook, set your Google Drive dataset path:
   ```python
   GDRIVE_DATASET_PATH = "/content/drive/MyDrive/datasets"  # Your path
   ```

5. **Run all cells**: The notebook will:
   - Mount Google Drive automatically
   - Load dataset directly from Drive (no download needed!)
   - Train the model for 50 epochs (~1-2 hours)
   - Save the best model

6. **Save model to Drive**: The trained model can be saved back to Google Drive for persistent storage

**Benefits of Google Drive Dataset:**
- ‚úÖ No need to re-download dataset each session
- ‚úÖ Dataset persists across Colab sessions
- ‚úÖ Faster startup time
- ‚úÖ Save trained models to Drive

**Colab Tips:**
- Batch size is reduced to 8 for Colab GPU memory constraints
- Training for 50 epochs is a good starting point; increase for better results

### Inference

Denoise a single audio file:

```bash
python inference.py --input noisy_audio.wav --output clean_audio.wav --checkpoint checkpoints/best_model.pt
```

### Evaluation

Evaluate model performance on the test set:

```bash
python evaluate.py --config config.yaml --checkpoint checkpoints/best_model.pt
```

**Metrics:**
| Metric | Description |
|--------|-------------|
| SNR | Signal-to-Noise Ratio |
| STOI | Short-Time Objective Intelligibility |
| PESQ | Perceptual Evaluation of Speech Quality (optional) |

### GUI Application

Launch the graphical interface:

```bash
python app.py
# or
python run_app.py
```

Features:
- Load and process audio files
- Visualize waveforms and spectrograms
- Compare before/after denoising
- Batch processing support

### Real-time Demo

Run real-time denoising with microphone input:

```bash
python realtime_demo.py
```

## Configuration

Edit `config.yaml` to customize training parameters:

```yaml
data:
  sample_rate: 16000
  segment_length: 32000  # 2 seconds

stft:
  n_fft: 512
  hop_length: 128
  win_length: 512

model:
  name: "UNetDenoiser"
  encoder_channels: [32, 64, 128, 256, 512]
  use_attention: true
  dropout: 0.1

training:
  batch_size: 16
  num_epochs: 100
  learning_rate: 0.0001
```

## Project Structure

```
speech_denoising/
‚îú‚îÄ‚îÄ app.py              # GUI application
‚îú‚îÄ‚îÄ run_app.py          # GUI launcher
‚îú‚îÄ‚îÄ train.py            # Training script
‚îú‚îÄ‚îÄ train_colab.ipynb   # Google Colab training notebook
‚îú‚îÄ‚îÄ inference.py        # Single-file inference
‚îú‚îÄ‚îÄ evaluate.py         # Model evaluation
‚îú‚îÄ‚îÄ demo.py             # Quick demo script
‚îú‚îÄ‚îÄ realtime_demo.py    # Real-time microphone demo
‚îú‚îÄ‚îÄ config.yaml         # Configuration file
‚îú‚îÄ‚îÄ download_dataset.py # Dataset download helper
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ dataset.py      # Dataset classes and dataloaders
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ unet.py         # U-Net model architecture
‚îÇ   ‚îî‚îÄ‚îÄ loss.py         # Loss functions
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ audio_utils.py  # Audio processing utilities
‚îÇ   ‚îî‚îÄ‚îÄ metrics.py      # Evaluation metrics
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

## Anti-Lazy Learning Features

V·∫•n ƒë·ªÅ "lazy learning" x·∫£y ra khi model h·ªçc c√°ch gi·∫£m volume thay v√¨ th·ª±c s·ª± l·ªçc noise (v√¨ gi·∫£m volume c≈©ng gi·∫£m loss). D·ª± √°n n√†y ƒë√£ ƒë∆∞·ª£c c·∫£i ti·∫øn v·ªõi c√°c t√≠nh nƒÉng sau:

### 1. SI-SDR Loss (Scale-Invariant Signal-to-Distortion Ratio)
- **Quan tr·ªçng nh·∫•t**: SI-SDR kh√¥ng b·ªã ƒë√°nh l·ª´a b·ªüi volume reduction
- Scale-invariant: Ch·ªâ quan t√¢m ch·∫•t l∆∞·ª£ng, kh√¥ng quan t√¢m √¢m l∆∞·ª£ng
- C·∫•u h√¨nh: `si_sdr_weight: 0.5` trong config.yaml

### 2. Energy Conservation Loss
- Ph·∫°t model n·∫øu nƒÉng l∆∞·ª£ng output kh√°c qu√° nhi·ªÅu so v·ªõi target
- NgƒÉn model gi·∫£m volume qu√° nhi·ªÅu (ratio ph·∫£i trong [0.6, 1.4])
- C·∫•u h√¨nh: `energy_weight: 0.1` trong config.yaml

### 3. Global Normalization
- Chu·∫©n h√≥a theo mean/std c·ªßa to√†n b·ªô training set
- Kh√¥ng d√πng per-file peak normalization (g√¢y inconsistent)
- Statistics ƒë∆∞·ª£c l∆∞u v√† s·ª≠ d·ª•ng l·∫°i cho inference

### 4. Post-Processing Amplitude Matching
- Output ƒë∆∞·ª£c match loudness v·ªõi input
- Tr√°nh v·∫•n ƒë·ªÅ "√¢m l∆∞·ª£ng gi·∫£m" sau kh·ª≠ nhi·ªÖu
- C√≥ th·ªÉ b·∫≠t/t·∫Øt: `--match_loudness` trong inference.py

### Ki·ªÉm tra Lazy Learning

```bash
python test_model_quality.py --checkpoint checkpoints/best_model.pt
```

Script n√†y s·∫Ω:
- T√≠nh Energy Ratio (n√™n g·∫ßn 1.0)
- T√≠nh Noise Reduction (n√™n > 50%)
- T√≠nh SI-SDR improvement (n√™n > 3 dB)
- Ch·∫©n ƒëo√°n v√† ƒë·ªÅ xu·∫•t c√°ch s·ª≠a

## Training Tips

### T·ªëi ∆∞u EarlyStopping
- TƒÉng `patience` l√™n 15-20 ƒë·ªÉ tr√°nh d·ª´ng s·ªõm
- B·∫≠t `restore_best_weights: true`
- Train √≠t nh·∫•t 100-150 epochs

### Ki·ªÉm tra Loss Function
- N·∫øu model gi·∫£m volume: tƒÉng `si_sdr_weight` v√† `energy_weight`
- N·∫øu output m√©o ti·∫øng: gi·∫£m `magnitude_weight`, tƒÉng `time_l1_weight`
- Theo d√µi c·∫£ val_loss v√† SI-SDR improvement

### Data Normalization
- KH√îNG d√πng peak normalization per-file
- D√πng global normalization (mean=0, std=1)
- ƒê·∫£m b·∫£o clean/noisy pairs ƒë∆∞·ª£c align ƒë√∫ng

## Notes

- **PESQ Installation**: PESQ requires C compilation. On Windows, install Microsoft Visual C++ Build Tools. The system works without PESQ if unavailable.
- **GPU Training**: Recommended for faster training. Enable with CUDA-compatible GPU.
- **Training Time**: ~2-4 hours on CPU, significantly faster on GPU.

## License

MIT License
